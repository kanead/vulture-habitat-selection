trk <- mk_track(inter_data, .x=long, .y=lat, .t=time, id = id,
crs = CRS("+init=epsg:4326"))
# Now it is easy to calculate day/night with either movement track
trk <- trk %>% time_of_day()
#' Save the class here (and apply it later after adding columns to the
#' object)
trk.class<-class(trk)
# nest by id
nesttrk<-trk%>%nest(-id)
nesttrk
#' We can add a columns to each nested column of data using purrr::map
trk<-trk %>% nest(-id) %>%
mutate(dir_abs = map(data, direction_abs,full_circle=TRUE, zero="N"),
dir_rel = map(data, direction_rel),
sl = map(data, step_lengths),
nsd_=map(data, nsd))%>%unnest()
#' Now, calculate month, year, hour, week of each observation and append these to the dataset
#' Unlike the movement charactersitics, these calculations can be done all at once,
#' since they do not utilize successive observations (like step lengths and turn angles do).
trk<-trk%>%
mutate(
week=week(t_),
month = month(t_, label=TRUE),
year=year(t_),
hour = hour(t_)
)
#' Now, we need to again tell R that this is a track (rather
#' than just a data frame)
class(trk)
class(trk)<-trk.class
#' Lets take a look at what we created
trk <- trk %>% group_by(id)
trk
# look at net-squared displacement
ggplot(trk, aes(x = t_, y=nsd_)) + geom_point()+
facet_wrap(~id, scales="free")
# Intermountain Vulture Tracking Dataset
# inter
# select inter data which is data from everything
inter_data <- filter(mydata, study == "inter")
inter_data
#' Check for duplicated observations (ones with same lat, long, timestamp,
#'  and individual identifier).
ind2<-inter_data %>% select(long, lat, id) %>%
duplicated
sum(ind2)
# remove them
inter_data$dups <- ind2
inter_data <- filter(inter_data,dups=="FALSE")
inter_data
# set the time column
levels(factor(inter_data$id))
# can look at an individual level with
(filter(inter_data,id=="105390"))
# all of the data is in the format of day-month-year
inter_data$New_time<-parse_date_time(x=inter_data$time,c("%d/%m/%Y %H:%M"))
# keep only the new time data
inter_data <- select(inter_data, New_time,long,lat,id,species,study)
inter_data <- rename(inter_data, time = New_time)
inter_data
# check the minimum time and the maximum time
min_time <- inter_data %>% group_by(id) %>% slice(which.min(time))
data.frame(min_time)
max_time <- inter_data %>% group_by(id) %>% slice(which.max(time))
data.frame(max_time)
# let's select just the AWBVs
inter_data <- filter(inter_data,species=="wb")
inter_data
#' filter extreme data based on a speed threshold
#' based on vmax which is km/hr
#' time needs to be labelled DateTime for these functions to work
library(SDLfilter)
names(inter_data)[names(inter_data) == 'time'] <- 'DateTime'
SDLfilterData<-ddfilter.speed(data.frame(inter_data), vmax = 60, method = 1)
length(SDLfilterData$DateTime)
#' rename everything as before
inter_data <- SDLfilterData
names(inter_data)[names(inter_data) == 'DateTime'] <- 'time'
# try the amt package
trk <- mk_track(inter_data, .x=long, .y=lat, .t=time, id = id,
crs = CRS("+init=epsg:4326"))
# Now it is easy to calculate day/night with either movement track
trk <- trk %>% time_of_day()
#' Save the class here (and apply it later after adding columns to the
#' object)
trk.class<-class(trk)
# nest by id
nesttrk<-trk%>%nest(-id)
nesttrk
#' We can add a columns to each nested column of data using purrr::map
trk<-trk %>% nest(-id) %>%
mutate(dir_abs = map(data, direction_abs,full_circle=TRUE, zero="N"),
dir_rel = map(data, direction_rel),
sl = map(data, step_lengths),
nsd_=map(data, nsd))%>%unnest()
#' Now, calculate month, year, hour, week of each observation and append these to the dataset
#' Unlike the movement charactersitics, these calculations can be done all at once,
#' since they do not utilize successive observations (like step lengths and turn angles do).
trk<-trk%>%
mutate(
week=week(t_),
month = month(t_, label=TRUE),
year=year(t_),
hour = hour(t_)
)
#' Now, we need to again tell R that this is a track (rather
#' than just a data frame)
class(trk)
class(trk)<-trk.class
#' Lets take a look at what we created
trk <- trk %>% group_by(id)
trk
# look at net-squared displacement
ggplot(trk, aes(x = t_, y=nsd_)) + geom_point()+
facet_wrap(~id, scales="free")
# Mendelsohn Namibia Vulture Tracking Dataset
# mend
# select mend data which is data from everything
mend_data <- filter(mydata, study == "mend")
mend_data
#' Check for duplicated observations (ones with same lat, long, timestamp,
#'  and individual identifier).
ind2<-mend_data %>% select(long, lat, id) %>%
duplicated
sum(ind2)
# remove them
mend_data$dups <- ind2
mend_data <- filter(mend_data,dups=="FALSE")
mend_data
# set the time column
levels(factor(mend_data$id))
# can look at an individual level with
(filter(mend_data,id=="WBV1__44782"))
# all of the data is in the format of day-month-year
mend_data$New_time<-parse_date_time(x=mend_data$time,c("%d/%m/%Y %H:%M"))
# keep only the new time data
mend_data <- select(mend_data, New_time,long,lat,id,species,study)
mend_data <- rename(mend_data, time = New_time)
mend_data
# check the minimum time and the maximum time
min_time <- mend_data %>% group_by(id) %>% slice(which.min(time))
data.frame(min_time)
max_time <- mend_data %>% group_by(id) %>% slice(which.max(time))
data.frame(max_time)
# let's select just the CVs
mend_data <- filter(mend_data,species=="cv")
mend_data
#' filter extreme data based on a speed threshold
#' based on vmax which is km/hr
#' time needs to be labelled DateTime for these functions to work
library(SDLfilter)
names(mend_data)[names(mend_data) == 'time'] <- 'DateTime'
SDLfilterData<-ddfilter.speed(data.frame(mend_data), vmax = 60, method = 1)
length(SDLfilterData$DateTime)
#' rename everything as before
mend_data <- SDLfilterData
names(mend_data)[names(mend_data) == 'DateTime'] <- 'time'
# try the amt package
trk <- mk_track(mend_data, .x=long, .y=lat, .t=time, id = id,
crs = CRS("+init=epsg:4326"))
# Now it is easy to calculate day/night with either movement track
trk <- trk %>% time_of_day()
#' Save the class here (and apply it later after adding columns to the
#' object)
trk.class<-class(trk)
# nest by id
nesttrk<-trk%>%nest(-id)
nesttrk
#' We can add a columns to each nested column of data using purrr::map
trk<-trk %>% nest(-id) %>%
mutate(dir_abs = map(data, direction_abs,full_circle=TRUE, zero="N"),
dir_rel = map(data, direction_rel),
sl = map(data, step_lengths),
nsd_=map(data, nsd))%>%unnest()
#' Now, calculate month, year, hour, week of each observation and append these to the dataset
#' Unlike the movement charactersitics, these calculations can be done all at once,
#' since they do not utilize successive observations (like step lengths and turn angles do).
trk<-trk%>%
mutate(
week=week(t_),
month = month(t_, label=TRUE),
year=year(t_),
hour = hour(t_)
)
#' Now, we need to again tell R that this is a track (rather
#' than just a data frame)
class(trk)
class(trk)<-trk.class
#' Lets take a look at what we created
trk <- trk %>% group_by(id)
trk
#' look at net-squared displacement
ggplot(trk, aes(x = t_, y=nsd_)) + geom_point()+
facet_wrap(~id, scales="free")
#' some data points look a little off
#' we can identify them to investiage further and remove them
#' if needs be
filter(trk,id=="CV5__44780" & nsd_ > 30)
#' ## SSF prep
#'
#' SSFs assume that data have been collected at regular time intervals.
#' We can use the track_resample function to regularize the trajectory so that
#' all points are located within some tolerence of each other in time. To figure
#' out a meaningful tolerance range, we should calculate time differences between
#' locations & look at as a function of individual.
(timestats<-trk %>% nest(-id) %>% mutate(sr = map(data, summarize_sampling_rate)) %>%
dplyr::select(id, sr) %>% unnest)
#' Time intervals range depending on the individual.
#'Lets add on the time difference to each obs.
trk<-trk %>% group_by(id) %>% mutate(dt_ = t_ - lag(t_, default = NA))
trk
#' select individuals that have temporal resolution of ~ 1hr
trk<- filter(trk,id=="CV1__44780"|
id=="CV2_44781"|
id=="CV3__53230"|
id=="CV4__53229"|
id=="CV5__44780"|
id=="CV6_44782")
# need to run timestats again for the subsetted dataframe so that the IDs match up below
(timestats<-trk %>% nest(-id) %>% mutate(sr = map(data, summarize_sampling_rate)) %>%
dplyr::select(id, sr) %>% unnest)
# Morgan Pfeiffer's SA Vulture Tracking Dataset
# select Morgan's data
morgan_data <- filter(mydata, study == "pfeiffer")
morgan_data
# drop missing rows
morgan_data<- morgan_data %>% drop_na
#' Check for duplicated observations (ones with same lat, long, timestamp,
#'  and individual identifier).
ind2<-morgan_data %>% select(long, lat, id) %>%
duplicated
sum(ind2)
# remove them
morgan_data$dups <- ind2
morgan_data <- filter(morgan_data,dups=="FALSE")
morgan_data
# set the time column
# some are in day/month/year format e.g. X016_Complete; X020_Final; X021_Final; X022_Complete; X032_Final; X033_Complete;
# some are in month/day/year format e.g. X023; X027; X042; X050; X051; X052; X053; X055; X056; X057; X071
levels(factor(morgan_data$id))
temp1<-filter(morgan_data,
id == "X016_Complete" |
id=="X021_Final" |
id == "X020_Final" |
id == "X021_Final" |
id == "X022_Complete" |
id == "X032_Final" |
id == "X033_Complete" ); tail(temp1) ;head(temp1)
temp1
temp1$New_time<-parse_date_time(x=temp1$time,c("%d/%m/%Y %H:%M"))
tail(temp1)
temp2<-filter(morgan_data,
id == "X023" |
id == "X027" |
id == "X042" |
id == "X050" |
id == "X051" |
id == "X052" |
id == "X053" |
id == "X055" |
id == "X056" |
id == "X057" |
id == "X071" ); tail(temp2) ;head(temp2)
temp2
temp2$New_time<-parse_date_time(x=temp2$time,c("%m/%d/%Y %H:%M"))
tail(temp2)
# stick them back together again
morgan_data <- full_join(temp1,temp2)
morgan_data
# Morgan's data is in reverse order of time
# sort by the bird ID and reverse the order
morgan_data <- morgan_data %>% group_by(id)  %>%
arrange(New_time, .by_group = TRUE)
morgan_data
# keep only the new time data
morgan_data <- select(morgan_data, New_time,long,lat,id,species,study)
morgan_data <- rename(morgan_data, time = New_time)
# check the minimum time and the maximum time
min_time <- morgan_data %>% group_by(id) %>% slice(which.min(New_time))
data.frame(min_time)
max_time <- morgan_data %>% group_by(id) %>% slice(which.max(New_time))
data.frame(max_time)
#' filter extreme data based on a speed threshold
#' based on vmax which is km/hr
#' time needs to be labelled DateTime for these functions to work
library(SDLfilter)
names(morgan_data)[names(morgan_data) == 'time'] <- 'DateTime'
SDLfilterData<-ddfilter.speed(data.frame(morgan_data), vmax = 60, method = 1)
# Morgan Pfeiffer's SA Vulture Tracking Dataset
# select Morgan's data
morgan_data <- filter(mydata, study == "pfeiffer")
morgan_data
# drop missing rows
morgan_data<- morgan_data %>% drop_na
#' Check for duplicated observations (ones with same lat, long, timestamp,
#'  and individual identifier).
ind2<-morgan_data %>% select(long, lat, id) %>%
duplicated
sum(ind2)
# remove them
morgan_data$dups <- ind2
morgan_data <- filter(morgan_data,dups=="FALSE")
morgan_data
# set the time column
# some are in day/month/year format e.g. X016_Complete; X020_Final; X021_Final; X022_Complete; X032_Final; X033_Complete;
# some are in month/day/year format e.g. X023; X027; X042; X050; X051; X052; X053; X055; X056; X057; X071
levels(factor(morgan_data$id))
temp1<-filter(morgan_data,
id == "X016_Complete" |
id=="X021_Final" |
id == "X020_Final" |
id == "X021_Final" |
id == "X022_Complete" |
id == "X032_Final" |
id == "X033_Complete" ); tail(temp1) ;head(temp1)
temp1
temp1$New_time<-parse_date_time(x=temp1$time,c("%d/%m/%Y %H:%M"))
tail(temp1)
temp2<-filter(morgan_data,
id == "X023" |
id == "X027" |
id == "X042" |
id == "X050" |
id == "X051" |
id == "X052" |
id == "X053" |
id == "X055" |
id == "X056" |
id == "X057" |
id == "X071" ); tail(temp2) ;head(temp2)
temp2
temp2$New_time<-parse_date_time(x=temp2$time,c("%m/%d/%Y %H:%M"))
tail(temp2)
# stick them back together again
morgan_data <- full_join(temp1,temp2)
morgan_data
# Morgan's data is in reverse order of time
# sort by the bird ID and reverse the order
morgan_data <- morgan_data %>% group_by(id)  %>%
arrange(New_time, .by_group = TRUE)
morgan_data
# check the minimum time and the maximum time
min_time <- morgan_data %>% group_by(id) %>% slice(which.min(New_time))
data.frame(min_time)
max_time <- morgan_data %>% group_by(id) %>% slice(which.max(New_time))
data.frame(max_time)
# keep only the new time data
morgan_data <- select(morgan_data, New_time,long,lat,id,species,study)
morgan_data <- rename(morgan_data, time = New_time)
#' filter extreme data based on a speed threshold
#' based on vmax which is km/hr
#' time needs to be labelled DateTime for these functions to work
library(SDLfilter)
names(morgan_data)[names(morgan_data) == 'time'] <- 'DateTime'
SDLfilterData<-ddfilter.speed(data.frame(morgan_data), vmax = 60, method = 1)
length(SDLfilterData$DateTime)
#' rename everything as before
morgan_data <- SDLfilterData
names(morgan_data)[names(morgan_data) == 'DateTime'] <- 'time'
# try the amt package
trk <- mk_track(morgan_data, .x=long, .y=lat, .t=time, id = id,
crs = CRS("+init=epsg:4326"))
# Now it is easy to calculate day/night with either movement track
trk <- trk %>% time_of_day()
#' Save the class here (and apply it later after adding columns to the
#' object)
trk.class<-class(trk)
# nest by id
nesttrk<-trk%>%nest(-id)
nesttrk
#' We can add a columns to each nested column of data using purrr::map
trk<-trk %>% nest(-id) %>%
mutate(dir_abs = map(data, direction_abs,full_circle=TRUE, zero="N"),
dir_rel = map(data, direction_rel),
sl = map(data, step_lengths),
nsd_=map(data, nsd))%>%unnest()
#' Now, calculate month, year, hour, week of each observation and append these to the dataset
#' Unlike the movement charactersitics, these calculations can be done all at once,
#' since they do not utilize successive observations (like step lengths and turn angles do).
trk<-trk%>%
mutate(
week=week(t_),
month = month(t_, label=TRUE),
year=year(t_),
hour = hour(t_)
)
#' Now, we need to again tell R that this is a track (rather
#' than just a data frame)
class(trk)
class(trk)<-trk.class
#' Lets take a look at what we created
trk <- trk %>% group_by(id)
trk
#' ### Absolute angles (for each movement) relative to North
#' We could use a rose diagram (below) to depict the distribution of angles.
#+fig.height=12, fig.width=12
ggplot(trk, aes(x = dir_abs, y=..density..)) + geom_histogram(breaks = seq(0,360, by=20))+
coord_polar(start = 0) + theme_minimal() +
scale_fill_brewer() + ylab("Density") + ggtitle("Angles Direct") +
scale_x_continuous("", limits = c(0, 360), breaks = seq(0, 360, by=20),
labels = seq(0, 360, by=20))+
facet_wrap(~id)
#' ### Turning angles
#'
#' Note: a 0 indicates the animal continued to move in a straight line, a 180
#' indicates the animal turned around (but note, resting + measurement error often can
#' make it look like the animal turned around).
#+fig.height=12, fig.width=12
ggplot(trk, aes(x = dir_rel, y=..density..)) + geom_histogram(breaks = seq(-180,180, by=20))+
coord_polar(start = 0) + theme_minimal() +
scale_fill_brewer() + ylab("Density") + ggtitle("Angles Direct") +
scale_x_continuous("", limits = c(-180, 180), breaks = seq(-180, 180, by=20),
labels = seq(-180, 180, by=20))+
facet_wrap(~id)
#' ### Turning angles as histograms
#+fig.height=12, fig.width=12
ggplot(trk, aes(x = dir_rel)) +  geom_histogram(breaks = seq(-180,180, by=20))+
theme_minimal() +
scale_fill_brewer() + ylab("Count") + ggtitle("Angles Relative") +
scale_x_continuous("", limits = c(-180, 180), breaks = seq(-180, 180, by=20),
labels = seq(-180, 180, by=20))+facet_wrap(~id, scales="free")
#' ### Net-squared displacement over time for each individual
#+fig.height=12, fig.width=12
ggplot(trk, aes(x = t_, y=nsd_)) + geom_point()+
facet_wrap(~id, scales="free")
# WBV Namibia Vulture Tracking Dataset
# ga_nam
# select ga_nam data which is data from everything
ga_nam <- filter(mydata, study == "ga_nam")
ga_nam
#' Check for duplicated observations (ones with same lat, long, timestamp,
#'  and individual identifier).
ind2<-ga_nam %>% select(long, lat, id) %>%
duplicated
sum(ind2)
# remove them
ga_nam$dups <- ind2
ga_nam <- filter(ga_nam,dups=="FALSE")
ga_nam
# set the time column
levels(factor(ga_nam$id))
# can look at an individual level with
(filter(ga_nam,id=="5864"))
# all of the data is in the format of day-month-year
ga_nam$New_time<-parse_date_time(x=ga_nam$time,c("%d/%m/%Y %H:%M"))
# keep only the new time data
ga_nam <- select(ga_nam, New_time,long,lat,id,species,study)
ga_nam <- rename(ga_nam, time = New_time)
ga_nam
# check the minimum time and the maximum time
min_time <- ga_nam %>% group_by(id) %>% slice(which.min(time))
data.frame(min_time)
max_time <- ga_nam %>% group_by(id) %>% slice(which.max(time))
data.frame(max_time)
#' one of the IDs (5863) has a date in 2025!
#' This seems to be only the last few rows
#' We can delete anything that comes after a certain date
ga_nam <- ga_nam %>% filter(time < "2019-01-01")
#' check the dates again
max_time <- ga_nam %>% group_by(id) %>% slice(which.max(time))
data.frame(max_time)
#' let's select just the AWBVs
#' redundant here because they're all AWBVs
ga_nam <- filter(ga_nam,species=="wb")
ga_nam
#' filter extreme data based on a speed threshold
#' based on vmax which is km/hr
#' time needs to be labelled DateTime for these functions to work
library(SDLfilter)
names(ga_nam)[names(ga_nam) == 'time'] <- 'DateTime'
SDLfilterData<-ddfilter.speed(data.frame(ga_nam), vmax = 60, method = 1)
length(SDLfilterData$DateTime)
#' rename everything as before
ga_nam <- SDLfilterData
names(ga_nam)[names(ga_nam) == 'DateTime'] <- 'time'
# try the amt package
trk <- mk_track(ga_nam, .x=long, .y=lat, .t=time, id = id,
crs = CRS("+init=epsg:4326"))
# Now it is easy to calculate day/night with either movement track
trk <- trk %>% time_of_day()
#' Save the class here (and apply it later after adding columns to the
#' object)
trk.class<-class(trk)
# nest by id
nesttrk<-trk%>%nest(-id)
nesttrk
#' We can add a columns to each nested column of data using purrr::map
trk<-trk %>% nest(-id) %>%
mutate(dir_abs = map(data, direction_abs,full_circle=TRUE, zero="N"),
dir_rel = map(data, direction_rel),
sl = map(data, step_lengths),
nsd_=map(data, nsd))%>%unnest()
#' Now, calculate month, year, hour, week of each observation and append these to the dataset
#' Unlike the movement charactersitics, these calculations can be done all at once,
#' since they do not utilize successive observations (like step lengths and turn angles do).
trk<-trk%>%
mutate(
week=week(t_),
month = month(t_, label=TRUE),
year=year(t_),
hour = hour(t_)
)
#' Now, we need to again tell R that this is a track (rather
#' than just a data frame)
class(trk)
class(trk)<-trk.class
#' Lets take a look at what we created
trk <- trk %>% group_by(id)
trk
#' look at net-squared displacement
ggplot(trk, aes(x = t_, y=nsd_)) + geom_point()+
facet_wrap(~id, scales="free")
